{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "DataTau Web Scrape"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "from urllib2 import urlopen\n",
      "from time import sleep\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import pprint as pp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "First Page"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The structure of Datatau pages is a very straightforward one. The only complicated element is that the page next link doesn't seem to be a structured one. Let's first get the links on the first page"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "BASE_URL = 'http://www.datatau.com'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_soup(url):\n",
      "    html = urlopen(url).read()\n",
      "    return BeautifulSoup(html)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following method takes a URL as a parameter and returns the story name, link, points and user"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_links_titles(url):\n",
      "    soup = make_soup(url)\n",
      "    table = soup.find(\"table\", {'border':'0', 'cellpadding':'0'})\n",
      "    page_data = [] \n",
      "    for td in table.findAll('td', 'title')[1:]:\n",
      "        try: \n",
      "            st = td.findNext('td', 'subtext')   \n",
      "            page_data.append({'name' : td.find('a').string, 'link' : td.find('a')['href'],\n",
      "                              'points' : st.find('span').string, 'user' : st.find('a').string })\n",
      "        except:\n",
      "            pass\n",
      "    return page_data\n",
      "\n",
      "page_data = get_links_titles(BASE_URL)\n",
      "page_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "[{'link': 'http://sumsar.net/blog/2014/06/bayesian-first-aid-prop-test/',\n",
        "  'name': u'Bayesian First Aid: Test of Proportions',\n",
        "  'points': u'4 points',\n",
        "  'user': u'rasmusab'},\n",
        " {'link': 'http://mlwave.com/predicting-click-through-rates-with-online-machine-learning/',\n",
        "  'name': u'Predicting Click-Through-Rates with Online Machine Learning',\n",
        "  'points': u'5 points',\n",
        "  'user': u'nofreehunch'},\n",
        " {'link': 'http://bost.ocks.org/mike/algorithms/',\n",
        "  'name': u'Visualizing Algorithms',\n",
        "  'points': u'6 points',\n",
        "  'user': u'rohit'},\n",
        " {'link': 'http://www.analyticsvidhya.com/blog/2014/06/deep-learning-attention/',\n",
        "  'name': u'What is deep learning and why is it getting so much attention?',\n",
        "  'points': u'6 points',\n",
        "  'user': u'kunaljain'},\n",
        " {'link': 'https://www.dataorigami.net/',\n",
        "  'name': u'Data Science Screencasts',\n",
        "  'points': u'7 points',\n",
        "  'user': u'cmrn_dp'},\n",
        " {'link': 'https://www.youtube.com/watch?v=MG_nOddk01E',\n",
        "  'name': u'Google I/O 2014 - Biologically inspired models of intelligence',\n",
        "  'points': u'2 points',\n",
        "  'user': u'tfturing'},\n",
        " {'link': 'http://www.chrisstucchio.com/blog/2014/equal_weights.html',\n",
        "  'name': u'Why a pro/con list is 75% as good as your fancy machine learning algorithm',\n",
        "  'points': u'5 points',\n",
        "  'user': u'yummyfajitas'},\n",
        " {'link': 'http://machinelearningmastery.com/quick-and-dirty-data-analysis-with-pandas/',\n",
        "  'name': u'Quick and Dirty Data Analysis with Pandas',\n",
        "  'points': u'7 points',\n",
        "  'user': u'jasonb'},\n",
        " {'link': 'https://www.youtube.com/watch?v=h2Ixpfn-DTg',\n",
        "  'name': u'Intro to Deep Learning on Hadoop',\n",
        "  'points': u'9 points',\n",
        "  'user': u'agibsonccc'},\n",
        " {'link': 'http://yahoolabs.tumblr.com/post/89783581601/one-hundred-million-creative-commons-flickr-images-for',\n",
        "  'name': u'One Hundred Million Creative Commons Flickr Images for Research',\n",
        "  'points': u'4 points',\n",
        "  'user': u'ebellm'},\n",
        " {'link': 'http://www.analyticsvidhya.com/blog/2014/05/hadoop-simplified/',\n",
        "  'name': u'What is Hadoop? \\u2013 Simplified!',\n",
        "  'points': u'7 points',\n",
        "  'user': u'tavish'},\n",
        " {'link': 'http://jvns.ca/blog/2014/06/19/machine-learning-isnt-kaggle-competitions/',\n",
        "  'name': u\"Machine learning isn't Kaggle competitions\",\n",
        "  'points': u'18 points',\n",
        "  'user': u'jvns'},\n",
        " {'link': 'https://dbaumgartel.wordpress.com/2014/06/15/the-kaggle-higgs-challenge-beat-the-benchmarks-with-scikit-learn/',\n",
        "  'name': u'The Kaggle Higgs Challenge \\u2013 Beat the benchmarks with scikit-learn',\n",
        "  'points': u'5 points',\n",
        "  'user': u'tfturing'},\n",
        " {'link': 'http://slantedwindows.com/reservoir-sampling-made-visual/',\n",
        "  'name': u'Reservoir Sampling Made Visual',\n",
        "  'points': u'3 points',\n",
        "  'user': u'kk'},\n",
        " {'link': 'http://codeascraft.com/2014/06/18/conjecture-scalable-machine-learning-in-hadoop-with-scalding/',\n",
        "  'name': u'Conjecture: Scalable Machine Learning in Hadoop with Scalding (Etsy)',\n",
        "  'points': u'4 points',\n",
        "  'user': u'kk'},\n",
        " {'link': 'http://lepisma.svbtle.com/extreme-learning-machines-with-julia',\n",
        "  'name': u'Extreme Learning Machine with julia',\n",
        "  'points': u'6 points',\n",
        "  'user': u'lepisma'},\n",
        " {'link': 'https://github.com/ogrisel/notebooks',\n",
        "  'name': u'Some sample IPython notebooks for scikit-learn by Olivier Grisel',\n",
        "  'points': u'13 points',\n",
        "  'user': u'tfturing'},\n",
        " {'link': 'http://blog.yhathq.com/posts/yhat-sciencebox.html',\n",
        "  'name': u'Yhat Sciencebox',\n",
        "  'points': u'17 points',\n",
        "  'user': u'glamp'},\n",
        " {'link': 'https://github.com/karpathy/convnetjs',\n",
        "  'name': u'Convolutional Neural Networks in your browser',\n",
        "  'points': u'5 points',\n",
        "  'user': u'dzhibas'},\n",
        " {'link': 'http://neuralnetworksanddeeplearning.com/index.html',\n",
        "  'name': u'Neural networks and deep learning',\n",
        "  'points': u'10 points',\n",
        "  'user': u'Anon84'},\n",
        " {'link': 'http://insightdataengineering.com/blog/Insight_Data_Engineering_Fellows_Program_September_2014.html',\n",
        "  'name': u'Insight Data Engineering Fellows Program applications open for September 2014',\n",
        "  'points': u'10 points',\n",
        "  'user': u'pyk'},\n",
        " {'link': 'http://www.hakkalabs.co/articles/squares-machine-learning-infrastructure-applications',\n",
        "  'name': u\"Square's Machine Learning Infrastructure and Applications\",\n",
        "  'points': u'3 points',\n",
        "  'user': u'BKDev'},\n",
        " {'link': 'https://github.com/DrSkippy/Data-Science-45min-Intros',\n",
        "  'name': u'\"Introduction to Data Science\" by Gnip [iPython] ',\n",
        "  'points': u'7 points',\n",
        "  'user': u'ebellm'},\n",
        " {'link': 'http://www.hakkalabs.co/articles/practial-deep-learning-tutorial-deeplearning4j',\n",
        "  'name': u'Practical Deep Learning Lecture: Machine Perception (Deeplearning4j)',\n",
        "  'points': u'12 points',\n",
        "  'user': u'BKDev'},\n",
        " {'link': 'http://jakevdp.github.io/blog/2014/06/14/frequentism-and-bayesianism-4-bayesian-in-python/',\n",
        "  'name': u'How to be a Bayesian in Python: emcee vs. pymc vs. pystan',\n",
        "  'points': u'20 points',\n",
        "  'user': u'ebellm'},\n",
        " {'link': 'http://www.analyticsvidhya.com/blog/2014/06/books-data-scientists-or-aspiring-ones/',\n",
        "  'name': u'Must have books for data scientists (or aspiring ones)',\n",
        "  'points': u'9 points',\n",
        "  'user': u'kunaljain'},\n",
        " {'link': 'http://www.andresmh.com/nyctaxitrips/',\n",
        "  'name': u'All of NYC 2013 Taxi Trips Data',\n",
        "  'points': u'9 points',\n",
        "  'user': u'Anon84'},\n",
        " {'link': 'item?id=3336',\n",
        "  'name': u'Place to practice advanced SQL Interview questions?',\n",
        "  'points': u'2 points',\n",
        "  'user': u'Quietlike'},\n",
        " {'link': 'http://nbviewer.ipython.org/github/fisadev/world_cup_learning/blob/master/learn.ipynb',\n",
        "  'name': u'Ipynb: Predicting Winners of World Cup Matches',\n",
        "  'points': u'6 points',\n",
        "  'user': u'kk'},\n",
        " {'link': 'https://github.com/agibsonccc/java-deeplearning',\n",
        "  'name': u'Deeplearning4j - A deep-learning library for Java',\n",
        "  'points': u'16 points',\n",
        "  'user': u'kdavis'}]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This method simply retrieves the next page link by looking for the last td tag and appending the url to the base_url (www.datatau.com/link):\n",
      "\n",
      "One would argue that this is not an efficient method of retreiving the next page link and I'd agree! The only counter argument is that Web Scraping is often times a one off piece of task for a piece of analysis. For that reason it's better to be efficient then clever"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_next_page(base_url):\n",
      "    soup = make_soup(base_url)\n",
      "    table = soup.find(\"table\", {'border':'0', 'cellpadding':'0'})\n",
      "    for td in table.findAll('td', 'title')[-1:]:\n",
      "        sub_link = td.findNext('a')['href']\n",
      "        return base_url + sub_link\n",
      "        \n",
      "print(get_next_page(BASE_URL))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://www.datatau.com/x?fnid=TiA3LkKUQl\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Putting it together"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The next task is to put it all together in a repeatable fashion for all pages. The process will go something like this:\n",
      "\n",
      "1. Open http://www.datatau.com(/page) and scrape stories into list of dictionaries\n",
      "2. Scrape link to next page and store in seperate list.\n",
      "3. Now go to next page by using link placed into list \n",
      "4. Go to step 1 and repeat process until..... well. It breaks!!\n",
      "5. Convert list of dictionaries to pandas dataframe for analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def scrape_datatau(url):\n",
      "    link_data, next_pages = [], []  # lists for data \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "\n",
      "def css_styling():\n",
      "    styles = open('custom.css', 'r').read()\n",
      "    return HTML(styles)\n",
      "\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
        "    }\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        font-weight: bold;\n",
        "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
        "    }\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        font-style: oblique;\n",
        "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
        "    }\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        font-weight: bold;\n",
        "        font-style: oblique;\n",
        "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        width:800px;\n",
        "        margin-left:16% !important;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: Helvetica, serif;\n",
        "        text-align: center;\n",
        "    }\n",
        "    h4{\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "    div.text_cell_render{\n",
        "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 120%;\n",
        "        font-size: 120%;\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "    }\n",
        "    .prompt{\n",
        "        display: None;\n",
        "    }\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 22pt;\n",
        "        color: #4057A1;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    \n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }  \n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 192,
       "text": [
        "<IPython.core.display.HTML at 0x109ea44d0>"
       ]
      }
     ],
     "prompt_number": 192
    }
   ],
   "metadata": {}
  }
 ]
}